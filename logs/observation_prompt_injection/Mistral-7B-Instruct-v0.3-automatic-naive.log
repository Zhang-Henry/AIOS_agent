/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Attack started at: 2024-07-21 04:50
Namespace(llm_name='mistralai/Mistral-7B-Instruct-v0.3', max_gpu_memory={'0': '24GB', '1': '24GB', '2': '24GB', '3': '24GB'}, eval_device='cuda:0', max_new_tokens=256, scheduler_log_mode='console', agent_log_mode='console', llm_kernel_log_mode='console', use_backend=None, workflow_mode='automatic', attacker_tools_path='data/test.jsonl', tasks_path='data/agent_tasks/example/academic_agent_task.txt', agent_path='example/academic_agent_attack', observation_prompt_injection=True, plan_attack=False, action_attack=False, direct_prompt_injection=False, attack_type='naive')
Traceback (most recent call last):
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py", line 304, in hf_raise_for_status
    response.raise_for_status()
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/requests/models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/resolve/main/config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1722, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(url=url, proxies=proxies, timeout=etag_timeout, headers=headers)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1645, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 372, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 396, in _request_wrapper
    hf_raise_for_status(response)
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py", line 367, in hf_raise_for_status
    raise HfHubHTTPError(message, response=response) from e
huggingface_hub.utils._errors.HfHubHTTPError:  (Request ID: Root=1-669ccbf3-60de4d262da779415d78d668;07a8dcd2-8cd2-40a7-b3de-a0f3f4a20fff)

403 Forbidden: Please enable access to public gated repositories in your fine-grained token settings to view this repository..
Cannot access content at: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/resolve/main/config.json.
If you are trying to create or update content,make sure you have a token with the `write` role.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/utils/hub.py", line 402, in cached_file
    resolved_file = hf_hub_download(
                    ^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1221, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1325, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/huggingface_hub/file_download.py", line 1826, in _raise_on_head_call_error
    raise LocalEntryNotFoundError(
huggingface_hub.utils._errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/common/users/hz624/AgentAttackBench/main_attacker.py", line 156, in <module>
    main()
  File "/common/users/hz624/AgentAttackBench/main_attacker.py", line 74, in main
    llm = llms.LLMKernel(
          ^^^^^^^^^^^^^^^
  File "/common/users/hz624/AgentAttackBench/aios/llm_core/llms.py", line 48, in __init__
    self.model = OpenLLM(
                 ^^^^^^^^
  File "/common/users/hz624/AgentAttackBench/aios/llm_core/llm_classes/base_llm.py", line 33, in __init__
    self.load_llm_and_tokenizer()
  File "/common/users/hz624/AgentAttackBench/aios/llm_core/llm_classes/huggingface_native_llm.py", line 24, in load_llm_and_tokenizer
    self.model = MODEL_CLASS[self.model_type].from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 524, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 965, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/configuration_utils.py", line 632, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/configuration_utils.py", line 689, in _get_config_dict
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/utils/hub.py", line 445, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like mistralai/Mistral-7B-Instruct-v0.3 is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
