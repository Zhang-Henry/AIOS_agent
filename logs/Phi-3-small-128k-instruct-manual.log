/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The repository for microsoft/Phi-3-small-128k-instruct contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/microsoft/Phi-3-small-128k-instruct.
You can avoid this prompt in future by passing the argument `trust_remote_code=True`.

Do you wish to run the custom code? [y/N] Traceback (most recent call last):
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/dynamic_module_utils.py", line 613, in resolve_trust_remote_code
    answer = input(
             ^^^^^^
EOFError: EOF when reading a line

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/common/users/hz624/AgentAttackBench/main_attacker.py", line 126, in <module>
    main()
  File "/common/users/hz624/AgentAttackBench/main_attacker.py", line 53, in main
    llm = llms.LLMKernel(
          ^^^^^^^^^^^^^^^
  File "/common/users/hz624/AgentAttackBench/aios/llm_core/llms.py", line 48, in __init__
    self.model = OpenLLM(
                 ^^^^^^^^
  File "/common/users/hz624/AgentAttackBench/aios/llm_core/llm_classes/base_llm.py", line 33, in __init__
    self.load_llm_and_tokenizer()
  File "/common/users/hz624/AgentAttackBench/aios/llm_core/llm_classes/huggingface_native_llm.py", line 24, in load_llm_and_tokenizer
    self.model = MODEL_CLASS[self.model_type].from_pretrained(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 524, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py", line 968, in from_pretrained
    trust_remote_code = resolve_trust_remote_code(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/common/home/hz624/anaconda3/envs/AIOS/lib/python3.11/site-packages/transformers/dynamic_module_utils.py", line 626, in resolve_trust_remote_code
    raise ValueError(
ValueError: The repository for microsoft/Phi-3-small-128k-instruct contains custom code which must be executed to correctly load the model. You can inspect the repository content at https://hf.co/microsoft/Phi-3-small-128k-instruct.
Please pass the argument `trust_remote_code=True` to allow custom code to be run.
